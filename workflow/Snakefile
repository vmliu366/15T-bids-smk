# TODO:
#  - [ ] T1-FLASH processing 
#        [ ] get FLASH images, convert to BIDS format 
#        [ ] extract json info from scanner 
#        [ ] perform N4BiasFieldCorrection 

from glob import glob
from snakebids import bids
import os 
from shutil import which
from subprocess import check_output
from snakebids import set_bids_spec
set_bids_spec("v0_11_0")

configfile: 'config.yml'
config.setdefault('output_dir', './output')
c3d = config["c3d"]
c4d = config["c4d"]

if not config['input_dir']:
    raise ValueError("Please provide --config input_dir=/path/to/tar/")

if 'subjects' not in config:
    tar_files = glob(os.path.join(config['input_dir'], '*.tar')) # expects the /input/dir to contain .tar
    config['subjects'] = [os.path.splitext(os.path.basename(f))[0] for f in tar_files] # separating & grabbing first element
    config['tarfiles'] = {s: os.path.join(config['input_dir'], f"{s}.tar") for s in config['subjects']} # creating dict of {'sub':'/path/to/sub.tar'}

def out_path(path):
    return os.path.join(config['output_dir'], path)

rule all:
    input:
        niftis=expand(out_path('niftis/sub-{subject}'),subject=config['tarfiles'].keys()),
        uni=expand(bids(root=out_path('bids'),subject='{subject}',acq='mp2rage',datatype='anat',desc='UNI',suffix='T1w',extension='.nii.gz'),
                subject=config['tarfiles'].keys()),
        uniden=expand(bids(root=out_path('bids'),subject='{subject}',acq='mp2rage',datatype='anat',desc='UNI-DEN',suffix='T1w',extension='.nii.gz'),
                subject=config['tarfiles'].keys()),
        method_jsons=expand(bids(root=out_path('bids'),subject='{subject}',acq='mp2rage',datatype='anat',desc='UNI',suffix='T1w',extension='.json'),
                subject=config['tarfiles'].keys()
        ),
#        dwi=expand(bids(root='bids',subject='{subject}',acq='{acq}',datatype='dwi',suffix='dwi.{ext}'),
#                subject=config['tarfiles'].keys(),
#                acq=['multishell','revb0'],
#                ext=['nii.gz','bval','bvec','json']
#            ),

#        mtsat=expand(bids(root='bids',subject='{subject}',acq='{acq}',datatype='anat',suffix='MTsat.{ext}'),
#                subject=config['tarfiles'].keys(),
#                acq=['MTw_mt-on', 'MTw_mt-off'],
#                ext=['nii.gz', 'json']
#            ),

        dd=out_path('bids/dataset_description.json')
    
rule all_mp2rage:
   input:
         uni=expand(bids(root=out_path('bids'),subject='{subject}',acq='mp2rage',datatype='anat',desc='UNI-DEN',suffix='T1w.nii.gz'),
                subject=config['tarfiles'].keys()),
         invs=expand(bids(root=out_path('work'),subject='{subject}',acq='mp2rage',datatype='anat',inv='{inv}',suffix='MP2RAGE.nii.gz'),
                subject=config['tarfiles'].keys(),
#                part=['mag','phase'],
                inv=[1,2]
                ),
      

checkpoint extract_tar:
    input:
        tarfile = lambda wildcards: config['tarfiles'][wildcards.subject]
    output:
        directory(out_path('dicoms/sub-{subject}'))
    shell: 
        'mkdir -p {output} && tar -C {output} -xvf {input}'

checkpoint dcm_to_nii:
    input:
        out_path('dicoms/sub-{subject}')
    output:
        directory(out_path('niftis/sub-{subject}'))
    shell:
        "mkdir -p {output} && dcm2niix -f '%s_%d' -o {output} -d 9 {input}"


rule cp_extra_bids:
    input:
        dd='resources/dataset_description.json',
        ignore='resources/bidsignore'
    output:
        dd=directory(out_path('bids/dataset_description.json')),
        ignore=directory(out_path('bids/.bidsignore'))
    shell:
        "mkdir -p {output.dd}/.. && " #chain commands 'logical AND'
        'cp {input.dd} {output.dd} && ' 
        'cp {input.ignore} {output.ignore}'

for module in config['modules']:
    include: f"rules/{module}.smk"
